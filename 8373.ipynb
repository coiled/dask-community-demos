{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdffd517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/dask/dask/issues/8373"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a486231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a42bf5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '~/Documents/notebooks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64df619e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.from_pandas(pd.DataFrame({\n",
    "        'part': [\"X\", \"Y\", \"Z\"],\n",
    "        'pd_int': pd.Series([1, 2, None], dtype=\"Int64\"),\n",
    "        'pd_str': pd.Series([\"a\", \"b\", None], dtype=\"string\"),\n",
    "        'pd_bool': pd.Series([True, False, None], dtype=\"boolean\"),\n",
    "        'int': pd.Series([1, 2, 3], dtype=\"int\"),\n",
    "        'str': pd.Series([\"a\", \"b\", None], dtype=\"str\"),\n",
    "        'bool': pd.Series([True, False, True], dtype=\"bool\"),\n",
    "    }), npartitions=1)\n",
    "df.to_parquet(path, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faffcc7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "part        object\n",
       "pd_int       Int64\n",
       "pd_str      string\n",
       "pd_bool    boolean\n",
       "int          int64\n",
       "str         object\n",
       "bool          bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd.read_parquet(path, engine='pyarrow').compute().dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c30c0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path2 = f'{path}/partitioned'\n",
    "df = dd.from_pandas(pd.DataFrame({\n",
    "        'part': [\"X\", \"Y\", \"Z\"],\n",
    "        'pd_int': pd.Series([1, 2, None], dtype=\"Int64\"),\n",
    "        'pd_str': pd.Series([\"a\", \"b\", None], dtype=\"string\"),\n",
    "        'pd_bool': pd.Series([True, False, None], dtype=\"boolean\"),\n",
    "        'int': pd.Series([1, 2, 3], dtype=\"int\"),\n",
    "        'str': pd.Series([\"a\", \"b\", None], dtype=\"str\"),\n",
    "        'bool': pd.Series([True, False, True], dtype=\"bool\"),\n",
    "    }), npartitions=1)\n",
    "df.to_parquet(path2, engine='pyarrow', partition_on=[\"part\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9bb4b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pd_int      float64\n",
       "pd_str       object\n",
       "pd_bool      object\n",
       "int           int64\n",
       "str          object\n",
       "bool           bool\n",
       "part       category\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd.read_parquet(path2, engine='pyarrow').compute().dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcd6a73a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pd_int      float64\n",
       "pd_str       object\n",
       "pd_bool      object\n",
       "int           int64\n",
       "str          object\n",
       "bool           bool\n",
       "part       category\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd.read_parquet(path2, engine='pyarrow')._meta.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "080cc8a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Appended dtypes differ.\n{('__null_dask_index__', 'int64'), ('pd_str', string[python]), ('pd_bool', BooleanDtype), ('pd_str', 'object'), ('bool', 'bool'), ('bool', dtype('bool')), ('part', dtype('O')), ('int', dtype('int64')), ('pd_bool', 'object'), ('__null_dask_index__', dtype('int64')), ('str', 'object'), ('pd_int', Int64Dtype()), ('int', 'int64'), ('pd_int', 'float64'), ('str', dtype('O'))}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hf/2s7qjx7j5ndc5220_qxv8y800000gn/T/ipykernel_6555/1882213619.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pyarrow'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartition_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"part\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/mambaforge/envs/dask-tutorial/lib/python3.8/site-packages/dask/dataframe/core.py\u001b[0m in \u001b[0;36mto_parquet\u001b[0;34m(self, path, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4438\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_parquet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4440\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mto_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_orc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mambaforge/envs/dask-tutorial/lib/python3.8/site-packages/dask/dataframe/io/parquet/core.py\u001b[0m in \u001b[0;36mto_parquet\u001b[0;34m(df, path, engine, compression, write_index, append, overwrite, ignore_divisions, partition_on, storage_options, custom_metadata, write_metadata_file, compute, compute_kwargs, schema, **kwargs)\u001b[0m\n\u001b[1;32m    636\u001b[0m     \u001b[0;31m# Engine-specific initialization steps to write the dataset.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;31m# Possibly create parquet metadata, and load existing stuff if appending\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m     meta, schema, i_offset = engine.initialize_write(\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mambaforge/envs/dask-tutorial/lib/python3.8/site-packages/dask/dataframe/io/parquet/arrow.py\u001b[0m in \u001b[0;36minitialize_write\u001b[0;34m(cls, df, fs, path, append, partition_on, ignore_divisions, division_info, schema, index_cols, **kwargs)\u001b[0m\n\u001b[1;32m    848\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;31m# TODO Coerce values for compatible but different dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    851\u001b[0m                     \"Appended dtypes differ.\\n{}\".format(\n\u001b[1;32m    852\u001b[0m                         \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m^\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Appended dtypes differ.\n{('__null_dask_index__', 'int64'), ('pd_str', string[python]), ('pd_bool', BooleanDtype), ('pd_str', 'object'), ('bool', 'bool'), ('bool', dtype('bool')), ('part', dtype('O')), ('int', dtype('int64')), ('pd_bool', 'object'), ('__null_dask_index__', dtype('int64')), ('str', 'object'), ('pd_int', Int64Dtype()), ('int', 'int64'), ('pd_int', 'float64'), ('str', dtype('O'))}"
     ]
    }
   ],
   "source": [
    "df.to_parquet(path2, engine='pyarrow', partition_on=[\"part\"], append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e69ea7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
